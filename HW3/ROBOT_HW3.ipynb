{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f27397c-e264-492b-9ca4-38099582446e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import robotic as ry\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import sys\n",
    "import open3d as o3d\n",
    "from scipy.spatial import cKDTree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec063aa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.1.10'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ry.version.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33278d27",
   "metadata": {},
   "source": [
    "### Part 1.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35e82454",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Initialize Configuration\n",
    "config = ry.Config()\n",
    "config.addFile(\"GFiles-HW3/environment.g\")\n",
    "\n",
    "# Camera Setup\n",
    "camera_view = ry.CameraView(config)\n",
    "cam_list = [\"camera1\", \"camera2\", \"camera3\", \"camera4\"]\n",
    "point_cloud_data = np.empty((0, 3))\n",
    "\n",
    "def transform_to_world_frame(frame_name, local_points):\n",
    "    \"\"\"\n",
    "    Transforms local frame points to world frame coordinates.\n",
    "\n",
    "    :param frame_name: Frame name for transformation.\n",
    "    :param local_points: Points in the local frame.\n",
    "    :return: Transformed points in world frame.\n",
    "    \"\"\"\n",
    "    frame_position = config.getFrame(frame_name).getPosition()\n",
    "    frame_rotation = config.getFrame(frame_name).getRotationMatrix()\n",
    "    return (frame_rotation @ local_points.T).T + frame_position\n",
    "\n",
    "def get_bounding_box(frames, margin=0.01, z_limit=0.713):\n",
    "    \"\"\"\n",
    "    Calculate bounding box for a group of frames.\n",
    "\n",
    "    :param frames: List of frame names.\n",
    "    :param margin: Margin around the bounding box.\n",
    "    :param z_limit: Minimum Z-coordinate threshold.\n",
    "    :return: Bounding box limits as min and max arrays.\n",
    "    \"\"\"\n",
    "    bbox_min = np.array([float(\"inf\")] * 3)\n",
    "    bbox_max = np.array([-float(\"inf\")] * 3)\n",
    "\n",
    "    for frame in frames:\n",
    "        frame_obj = config.getFrame(frame)\n",
    "        mesh = frame_obj.getMeshPoints()\n",
    "        world_coords = transform_to_world_frame(frame, mesh)\n",
    "\n",
    "        bbox_min = np.minimum(bbox_min, np.min(world_coords, axis=0) - margin)\n",
    "        bbox_max = np.maximum(bbox_max, np.max(world_coords, axis=0) + margin)\n",
    "\n",
    "    bbox_min[2] = max(bbox_min[2], z_limit)  # Ensure Z-min threshold\n",
    "    return bbox_min, bbox_max\n",
    "\n",
    "def filter_points_by_bbox(bbox_min, bbox_max, points):\n",
    "    \"\"\"\n",
    "    Filters points to those inside the bounding box.\n",
    "\n",
    "    :param bbox_min: Minimum bounding box coordinates.\n",
    "    :param bbox_max: Maximum bounding box coordinates.\n",
    "    :param points: Full point cloud.\n",
    "    :return: Points inside the bounding box.\n",
    "    \"\"\"\n",
    "    return points[\n",
    "        (points >= bbox_min).all(axis=1) & (points <= bbox_max).all(axis=1)\n",
    "    ]\n",
    "\n",
    "def compute_point_cloud_normals(points, neighbors=30, show=False):\n",
    "    \"\"\"\n",
    "    Computes normals for a given point cloud.\n",
    "\n",
    "    :param points: Input 3D points.\n",
    "    :param neighbors: K-nearest neighbors for normal estimation.\n",
    "    :param show: If True, visualize normals.\n",
    "    :return: Array of normal vectors.\n",
    "    \"\"\"\n",
    "    pcd = o3d.geometry.PointCloud()\n",
    "    pcd.points = o3d.utility.Vector3dVector(points)\n",
    "    pcd.estimate_normals(search_param=o3d.geometry.KDTreeSearchParamKNN(knn=neighbors))\n",
    "    pcd.orient_normals_consistent_tangent_plane(k=neighbors)\n",
    "\n",
    "    if show:\n",
    "        pcd.paint_uniform_color([1.0, 0.0, 0.0])\n",
    "        o3d.visualization.draw_geometries([pcd], point_show_normal=True)\n",
    "\n",
    "    return np.asarray(pcd.normals)\n",
    "\n",
    "# Merge Camera Point Clouds\n",
    "for cam in cam_list:\n",
    "    camera_view.setCamera(cam)\n",
    "    _, depth_image = camera_view.computeImageAndDepth(config)\n",
    "    cam_cloud = ry.depthImage2PointCloud(depth_image, camera_view.getFxycxy())\n",
    "    cam_cloud = cam_cloud.reshape(-1, 3)\n",
    "    world_cloud = transform_to_world_frame(cam, cam_cloud)\n",
    "    point_cloud_data = np.vstack([point_cloud_data, world_cloud])\n",
    "\n",
    "# Process Objects and Compute Normals\n",
    "objects = {\n",
    "    \"soap\": [\"soap_0\"],\n",
    "    \"rolling_pin\": [\"rolling-pin_0\", \"rolling-pin_1\"],\n",
    "    \"bottle\": [\"bottle_0\", \"bottle_1\", \"bottle_2\", \"bottle_3\", \"bottle_4\", \"bottle_5\", \"bottle_6\", \"bottle_7\"]\n",
    "}\n",
    "\n",
    "bounding_boxes = {}\n",
    "filtered_clouds = {}\n",
    "object_normals = {}\n",
    "\n",
    "for obj, obj_frames in objects.items():\n",
    "    bbox_min, bbox_max = get_bounding_box(obj_frames)\n",
    "    bounding_boxes[obj] = (bbox_min, bbox_max)\n",
    "\n",
    "    filtered_cloud = filter_points_by_bbox(bbox_min, bbox_max, point_cloud_data)\n",
    "    filtered_clouds[obj] = filtered_cloud\n",
    "\n",
    "    normals = compute_point_cloud_normals(filtered_cloud, neighbors=30, show=True)\n",
    "    object_normals[obj] = normals\n",
    "\n",
    "    # Visualize Point Cloud for Each Object\n",
    "    color = [255, 0, 0] if obj == \"soap\" else [0, 255, 0] if obj == \"rolling_pin\" else [0, 0, 255]\n",
    "    obj_frame = config.addFrame(f\"{obj}_cloud\")\n",
    "    obj_frame.setPointCloud(filtered_cloud, color)\n",
    "\n",
    "\n",
    "soap_normals = object_normals[\"soap\"]\n",
    "rolling_pin_normal = object_normals[\"rolling_pin\"]\n",
    "bottle_normals = object_normals[\"bottle\"]\n",
    "soap_points = filtered_clouds[\"soap\"]\n",
    "rolling_pin_points = filtered_clouds[\"rolling_pin\"]\n",
    "bottle_points = filtered_clouds[\"bottle\"]\n",
    "# Keep View Active\n",
    "config.view(True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1191fec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2170, 3)\n",
      "(2170, 3)\n"
     ]
    }
   ],
   "source": [
    "print(soap_points.shape)\n",
    "print(soap_normals.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23110e3d",
   "metadata": {},
   "source": [
    "### Part 1.2 (antipodal part takes some time; therefore, optimum pairs are written in hand after found through this algorithm) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b61b32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample_point_cloud(points, voxel_size=0.005):\n",
    "    \"\"\"\n",
    "    Downsamples the point cloud using a voxel grid.\n",
    "\n",
    "    :param points: (N, 3) array of point cloud data.\n",
    "    :param voxel_size: Size of the voxel grid. Smaller values retain more detail.\n",
    "    :return: Downsampled point cloud as a numpy array.\n",
    "    \"\"\"\n",
    "    # Convert to Open3D point cloud\n",
    "    pcd = o3d.geometry.PointCloud()\n",
    "    pcd.points = o3d.utility.Vector3dVector(points)\n",
    "    \n",
    "    # Apply voxel grid downsampling\n",
    "    downsampled_pcd = pcd.voxel_down_sample(voxel_size=voxel_size)\n",
    "    \n",
    "    # Convert back to numpy array\n",
    "    downsampled_points = np.asarray(downsampled_pcd.points)\n",
    "    return downsampled_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79527f02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Soap grasp pairs: 98833\n",
      "Rolling pin grasp pairs: 309044\n",
      "Bottle grasp pairs: 842821\n"
     ]
    }
   ],
   "source": [
    "def antipodal_grasp_detection(points, normals, angle_threshold=np.pi * 0.9, distance_range=(0.01, 0.1), visualize=False):\n",
    "    grasp_candidates = []\n",
    "    tree = cKDTree(points)  # Spatial index for efficient neighbor search\n",
    "\n",
    "    for i in range(len(points)):\n",
    "        neighbors = tree.query_ball_point(points[i], r=distance_range[1])  # Neighbors within max_distance\n",
    "        for j in neighbors:\n",
    "            if i >= j:  # Avoid duplicate or self-pairs\n",
    "                continue\n",
    "\n",
    "            distance = np.linalg.norm(points[i] - points[j])\n",
    "            if not (distance_range[0] <= distance <= distance_range[1]):\n",
    "                continue\n",
    "\n",
    "            normal1 = normals[i]\n",
    "            normal2 = normals[j]\n",
    "            angle = np.arccos(np.clip(np.dot(normal1, normal2), -1.0, 1.0))\n",
    "            if np.abs(angle - np.pi) < angle_threshold:\n",
    "                grasp_candidates.append((points[i], points[j]))\n",
    "\n",
    "    if visualize:\n",
    "        visualize_grasp_candidates(points, grasp_candidates)\n",
    "\n",
    "    return grasp_candidates\n",
    "\n",
    "\n",
    "def visualize_grasp_candidates(points, grasp_pairs):\n",
    "    \"\"\"\n",
    "    Visualizes grasp point pairs in a 3D space.\n",
    "\n",
    "    :param points: (N, 3) array of point cloud data.\n",
    "    :param grasp_pairs: List of grasp point pairs [(point1, point2)].\n",
    "    \"\"\"\n",
    "    pcd = o3d.geometry.PointCloud()\n",
    "    pcd.points = o3d.utility.Vector3dVector(points)\n",
    "    pcd.paint_uniform_color([0.5, 0.5, 0.5])  # Gray for point cloud\n",
    "\n",
    "    lines = []\n",
    "    line_colors = []\n",
    "    for grasp_pair in grasp_pairs:\n",
    "        lines.append([len(points), len(points) + 1])\n",
    "        line_colors.append([1.0, 0.0, 0.0])  # Red for grasp lines\n",
    "        pcd.points.extend(o3d.utility.Vector3dVector(np.array(grasp_pair)))\n",
    "\n",
    "    line_set = o3d.geometry.LineSet()\n",
    "    line_set.points = pcd.points\n",
    "    line_set.lines = o3d.utility.Vector2iVector(lines)\n",
    "    line_set.colors = o3d.utility.Vector3dVector(line_colors)\n",
    "\n",
    "    o3d.visualization.draw_geometries([pcd, line_set], width=800, height=600)\n",
    "\n",
    "\n",
    "voxel_size = 0.005  # Adjust based on your object's scale and detail required\n",
    "soap_points_downsampled = downsample_point_cloud(soap_points, voxel_size)\n",
    "rolling_pin_points_downsampled = downsample_point_cloud(rolling_pin_points, voxel_size)\n",
    "bottle_points_downsampled = downsample_point_cloud(bottle_points, voxel_size)\n",
    "\n",
    "# Use downsampled points in the detection function\n",
    "soap_grasp_points = antipodal_grasp_detection(soap_points_downsampled, soap_normals)\n",
    "rolling_pin_grasp_points = antipodal_grasp_detection(rolling_pin_points_downsampled, rolling_pin_normal)\n",
    "bottle_grasp_points = antipodal_grasp_detection(bottle_points_downsampled, bottle_normals)\n",
    "\n",
    "# Visualizing all grasp points\n",
    "print(f\"Soap grasp pairs: {len(soap_grasp_points)}\")\n",
    "print(f\"Rolling pin grasp pairs: {len(rolling_pin_grasp_points)}\")\n",
    "print(f\"Bottle grasp pairs: {len(bottle_grasp_points)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "45483d87-6cc2-40fd-9e62-35ad5395dc76",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" def antipodal_grasp_detection(points, normals, angle_threshold=np.pi * 0.9, distance_range=(0.01, 0.1), visualize=False):\n",
    "    \"\"\"\n",
    "   # Detects antipodal grasp points from point cloud data and surface normals.\n",
    "\n",
    "    #:param points: (N, 3) array of point cloud data.\n",
    "    #:param normals: (N, 3) array of normal vectors corresponding to the points.\n",
    "    #:param angle_threshold: Minimum angle (in radians) between normals for antipodal grasp.\n",
    "    #:param distance_range: Tuple of (min_distance, max_distance) for grasp width.\n",
    "    #:param visualize: Boolean, whether to visualize detected grasp points.\n",
    "    #:return: List of tuples [(point1, point2)] representing pairs of grasp points.\n",
    "    \"\"\"\n",
    "    grasp_candidates = []\n",
    "    num_points = points.shape[0]\n",
    "\n",
    "    for i in range(num_points):\n",
    "        for j in range(i + 1, num_points):\n",
    "            # Compute distance between points\n",
    "            distance = np.linalg.norm(points[i] - points[j])\n",
    "            if not (distance_range[0] <= distance <= distance_range[1]):\n",
    "                continue\n",
    "\n",
    "            # Compute angle between normals\n",
    "            normal1 = normals[i]\n",
    "            normal2 = normals[j]\n",
    "            dot_product = np.dot(normal1, normal2)\n",
    "            angle = np.arccos(np.clip(dot_product, -1.0, 1.0))  # Clip for numerical stability\n",
    "\n",
    "            if np.abs(angle - np.pi) < angle_threshold:\n",
    "                grasp_candidates.append((points[i], points[j]))\n",
    "\n",
    "    if visualize:\n",
    "        visualize_grasp_candidates(points, grasp_candidates)\n",
    "\n",
    "    return grasp_candidates \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1192e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_object_center(points):\n",
    "    \"\"\"\n",
    "    Computes the center of mass of the object based on its point cloud.\n",
    "\n",
    "    :param points: (N, 3) array of point cloud data.\n",
    "    :return: (3,) array representing the center of the object.\n",
    "    \"\"\"\n",
    "    return np.mean(points, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "140bece2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Soap Center: [-4.11669865e-05  3.99632171e-01  7.48119107e-01]\n",
      "Rolling Pin Center: [0.20275032 0.39684175 0.74995909]\n",
      "Bottle Center: [-0.18631975  0.34362194  0.75316998]\n"
     ]
    }
   ],
   "source": [
    "# Compute centers of mass for soap, rolling pin, and bottle\n",
    "soap_center = compute_object_center(soap_points)\n",
    "rolling_pin_center = compute_object_center(rolling_pin_points)\n",
    "bottle_center = compute_object_center(bottle_points)\n",
    "\n",
    "print(\"Soap Center:\", soap_center)\n",
    "print(\"Rolling Pin Center:\", rolling_pin_center)\n",
    "print(\"Bottle Center:\", bottle_center)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f530d73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_grasp_candidates(grasp_pairs, object_center, optimal_grasp_width):\n",
    "    \"\"\"\n",
    "    Scores grasp pairs based on distance to object center and optimal grasp width.\n",
    "\n",
    "    :param grasp_pairs: List of tuples [(point1, point2)] representing grasp pairs.\n",
    "    :param object_center: (3,) array of the object's center of mass.\n",
    "    :param optimal_grasp_width: Ideal grasp width for the robot gripper.\n",
    "    :return: Sorted list of scored grasp pairs [(score, (point1, point2))].\n",
    "    \"\"\"\n",
    "    scored_pairs = []\n",
    "    for p1, p2 in grasp_pairs:\n",
    "        # Compute center proximity\n",
    "        center_distance = np.linalg.norm((p1 + p2) / 2 - object_center)\n",
    "\n",
    "        # Compute grasp width deviation\n",
    "        grasp_width = np.linalg.norm(p1 - p2)\n",
    "        width_deviation = abs(grasp_width - optimal_grasp_width)\n",
    "\n",
    "        # Combine scores (lower is better)\n",
    "        score = center_distance + width_deviation\n",
    "        scored_pairs.append((score, (p1, p2)))\n",
    "\n",
    "    # Sort by score (ascending, best first)\n",
    "    scored_pairs.sort(key=lambda x: x[0])\n",
    "    return scored_pairs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "86b90563",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "soap_center = compute_object_center(soap_points)\n",
    "rolling_pin_center = compute_object_center(rolling_pin_points)\n",
    "bottle_center = compute_object_center(bottle_points)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29fa806f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "optimal_grasp_width = 0.05  \n",
    "\n",
    "# Score grasp pairs for soap\n",
    "scored_soap_grasps = score_grasp_candidates(soap_grasp_points, soap_center, optimal_grasp_width)\n",
    "\n",
    "# Score grasp pairs for rolling pin\n",
    "scored_rolling_pin_grasps = score_grasp_candidates(rolling_pin_grasp_points, rolling_pin_center, optimal_grasp_width)\n",
    "\n",
    "# Score grasp pairs for bottle\n",
    "scored_bottle_grasps = score_grasp_candidates(bottle_grasp_points, bottle_center, optimal_grasp_width)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c1527699",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_soap_grasps = scored_soap_grasps[:300]  # Select top 100 or something\n",
    "top_rolling_pin_grasps = scored_rolling_pin_grasps[:300]\n",
    "top_bottle_grasps = scored_bottle_grasps[:300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "df8b1d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_grasp_points(points, grasp_pairs, top_n=100):\n",
    "    \"\"\"\n",
    "    Visualizes top grasp point pairs in the point cloud.\n",
    "    \n",
    "    :param points: (N, 3) array of the full point cloud.\n",
    "    :param grasp_pairs: List of scored grasp pairs [(score, (point1, point2))].\n",
    "    :param top_n: Number of top grasp pairs to visualize.\n",
    "    \"\"\"\n",
    "    # Prepare the point cloud for visualization\n",
    "    pcd = o3d.geometry.PointCloud()\n",
    "    pcd.points = o3d.utility.Vector3dVector(points)\n",
    "    pcd.paint_uniform_color([0.5, 0.5, 0.5])  # Set point cloud to gray\n",
    "\n",
    "    # Prepare lines for visualization\n",
    "    lines = []\n",
    "    line_colors = []\n",
    "    line_points = points.copy()  # To hold the grasp points as well\n",
    "\n",
    "    for i, (_, (p1, p2)) in enumerate(grasp_pairs[:top_n]):  # Take top N grasp pairs\n",
    "        idx1 = len(line_points)\n",
    "        idx2 = idx1 + 1\n",
    "        line_points = np.vstack([line_points, p1, p2])\n",
    "        lines.append([idx1, idx2])\n",
    "        line_colors.append([1.0, 0.0, 0.0])  # Red color for the grasp line\n",
    "\n",
    "    # Convert to Open3D LineSet for visualization\n",
    "    line_set = o3d.geometry.LineSet()\n",
    "    line_set.points = o3d.utility.Vector3dVector(line_points)\n",
    "    line_set.lines = o3d.utility.Vector2iVector(lines)\n",
    "    line_set.colors = o3d.utility.Vector3dVector(line_colors)\n",
    "\n",
    "    # Visualize\n",
    "    o3d.visualization.draw_geometries([pcd, line_set], width=800, height=600)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a7f74185",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize top 100 grasp pairs for each object\n",
    "visualize_grasp_points(soap_points, scored_soap_grasps, top_n=100)\n",
    "visualize_grasp_points(rolling_pin_points, scored_rolling_pin_grasps, top_n=100)\n",
    "visualize_grasp_points(bottle_points, scored_bottle_grasps, top_n=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "135a1605",
   "metadata": {},
   "outputs": [],
   "source": [
    "#[array[0.01993792, 0.40039222, 0.73927161]), array([-0.0200274 ,  0.40008759,  0.73932566]] best for soap\n",
    "#[array[0.21628132, 0.41095367, 0.73980883]), array([0.18046731, 0.39471482, 0.73940787]] best for oklava\n",
    "#[array[-0.17950454,  0.28497283,  0.74082946]), array([-0.22031921,  0.28501877,  0.74036126]] best for sıvı sıkacagı"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94e2f4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "p1_soap = np.array([0.01993792, 0.40039222, 0.73927161])\n",
    "p2_soap = np.array([-0.0200274 ,  0.40008759,  0.73932566])\n",
    "p1_oklava = np.array([0.21628132, 0.41095367, 0.73980883])\n",
    "p2_oklava = np.array([0.18046731, 0.39471482, 0.73940787])\n",
    "p1_sıkacak = np.array([-0.17950454,  0.28497283,  0.74082946])\n",
    "p2_sıkacak = np.array([-0.22031921,  0.28501877,  0.74036126])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e6187e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_vector_sıkacak = p1_sıkacak - p2_sıkacak\n",
    "unit_normal_sıkacak = normal_vector_sıkacak / np.linalg.norm(normal_vector_sıkacak)\n",
    "\n",
    "normal_vector_sabun = p1_soap - p2_soap\n",
    "unit_normal_sabun = normal_vector_sabun / np.linalg.norm(normal_vector_sabun)\n",
    "\n",
    "normal_vector_oklava = p1_oklava - p2_oklava\n",
    "unit_normal_oklava = normal_vector_oklava / np.linalg.norm(normal_vector_oklava)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c996ff",
   "metadata": {},
   "source": [
    "### BOTOP PART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "251fe4bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<robotic._robotic.Frame at 0x7f0b6d798ab0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C = ry.Config()\n",
    "C.addFile(\"GFiles-HW3/environment.g\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "56249633",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C.view()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a2fb141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{ time: 0.015625, evals: 19, done: 1, feasible: 1, sos: 8.28112, f: 0, ineq: 0, eq: 0.13114 }\n",
      "{ time: 0.046875, evals: 1000, done: 1, feasible: 0, sos: 21.695, f: 0, ineq: 0, eq: 3.37787 }\n"
     ]
    }
   ],
   "source": [
    "juicer_grasp_point1 = p1_sıkacak\n",
    "juicer_grasp_point2 = p2_sıkacak\n",
    "\n",
    "\n",
    "juicer_grasp_middle = (juicer_grasp_point1 + juicer_grasp_point2) / 2\n",
    "\n",
    "juicer_gripper_point1 = juicer_grasp_middle + 0.04 * unit_normal_sıkacak\n",
    "juicer_gripper_point2 = juicer_grasp_middle - 0.04 * unit_normal_sıkacak\n",
    "\n",
    "\n",
    "C.addFrame(\"juicer_gripper_point1\").setPosition(juicer_gripper_point1).setShape(ry.ST.marker, size=[0.02])\n",
    "C.addFrame(\"juicer_gripper_point2\").setPosition(juicer_gripper_point2).setShape(ry.ST.marker, size=[0.02])\n",
    "\n",
    "\n",
    "juicer_sink_point = [0.6, 0.0, 0.7]  \n",
    "\n",
    "C.addFrame(\"juicer_sink_place\").setPosition(juicer_sink_point).setShape(ry.ST.marker, size=[0.02])\n",
    "\n",
    "komo = ry.KOMO()\n",
    "komo.setConfig(C, True)\n",
    "komo.setTiming(2., 1, 5., 0)\n",
    "komo.addControlObjective([], 0, 1e-0)\n",
    "komo.addObjective([], ry.FS.accumulatedCollisions, [], ry.OT.eq)\n",
    "komo.addObjective([], ry.FS.jointLimits, [], ry.OT.ineq)\n",
    "\n",
    "komo.addObjective([1.], ry.FS.poseDiff, ['l_gripper', 'juicer_gripper_point1'], ry.OT.eq, [1e1])\n",
    "komo.addObjective([2.], ry.FS.poseDiff, ['l_gripper', 'juicer_gripper_point2'], ry.OT.eq, [1e1])\n",
    "\n",
    "\n",
    "solver = ry.NLP_Solver()\n",
    "solver.setProblem(komo.nlp())\n",
    "solver.setOptions(stopTolerance=1e-2, verbose=4)\n",
    "ret = solver.solve()\n",
    "print(ret)\n",
    "\n",
    "komo.view(False, \"waypoints solution for juicer\")\n",
    "\n",
    "path_juicer = komo.getPath()\n",
    "\n",
    "juicer_sink_target = [-1, -0.3, 1]\n",
    "\n",
    "C.addFrame(\"juicer_sink_target\").setPosition(juicer_sink_target).setShape(ry.ST.marker, size=[0.02])\n",
    "\n",
    "komo = ry.KOMO()\n",
    "komo.setConfig(C, True)\n",
    "komo.setTiming(1., 1, 5., 0)  \n",
    "komo.addControlObjective([], 0, 1e-0)\n",
    "komo.addObjective([], ry.FS.accumulatedCollisions, [], ry.OT.eq)\n",
    "komo.addObjective([], ry.FS.jointLimits, [], ry.OT.ineq)\n",
    "\n",
    "\n",
    "komo.addObjective(\n",
    "    [1.], \n",
    "    ry.FS.poseDiff,\n",
    "    ['l_gripper', 'juicer_sink_target'], \n",
    "    ry.OT.eq,\n",
    "    [1e1]\n",
    ")\n",
    "\n",
    "solver = ry.NLP_Solver()\n",
    "solver.setProblem(komo.nlp())\n",
    "solver.setOptions(stopTolerance=1e-2, verbose=4)\n",
    "ret = solver.solve()\n",
    "print(ret)\n",
    "\n",
    "path2_juicer = komo.getPath()\n",
    "\n",
    "bot = ry.BotOp(C, False)\n",
    "bot.home(C)\n",
    "\n",
    "bot.move(path_juicer, [2.0, 3.0])\n",
    "while bot.getTimeToEnd() > 0:\n",
    "    bot.sync(C, 0.1)\n",
    "\n",
    "bot.gripperCloseGrasp(ry._left, 'bottle_0')  \n",
    "while not bot.gripperDone(ry._left):\n",
    "    bot.sync(C, 0.1)\n",
    "\n",
    "bot.move(path2_juicer, [3.0])  \n",
    "while bot.getTimeToEnd() > 0:\n",
    "    bot.sync(C, 0.1)\n",
    "\n",
    "bot.gripperMove(ry._left, width=.75, speed=.2)\n",
    "while not bot.gripperDone(ry._left):\n",
    "    bot.sync(C, .1)    \n",
    "\n",
    "bot.home(C)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b0726fec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{ time: 0, evals: 13, done: 1, feasible: 1, sos: 4.55128, f: 0, ineq: 0, eq: 0.140435 }\n",
      "{ time: 0.09375, evals: 900, done: 1, feasible: 0, sos: 21.6954, f: 0, ineq: 0, eq: 3.37943 }\n"
     ]
    }
   ],
   "source": [
    "rolling_pin_grasp_point1 = p1_oklava\n",
    "rolling_pin_grasp_point2 = p2_oklava\n",
    "\n",
    "rolling_pin_grasp_middle = (rolling_pin_grasp_point1 + rolling_pin_grasp_point2) / 2\n",
    "\n",
    "rolling_pin_gripper_point1 = rolling_pin_grasp_middle + 0.04 * unit_normal_oklava\n",
    "rolling_pin_gripper_point2 = rolling_pin_grasp_middle - 0.04 * unit_normal_oklava\n",
    "\n",
    "C.addFrame(\"rolling_pin_gripper_point1\").setPosition(rolling_pin_gripper_point1).setShape(ry.ST.marker, size=[0.02])\n",
    "C.addFrame(\"rolling_pin_gripper_point2\").setPosition(rolling_pin_gripper_point2).setShape(ry.ST.marker, size=[0.02])\n",
    "\n",
    "rolling_pin_sink_point = [0.6, 0.0, 0.7] \n",
    "\n",
    "C.addFrame(\"rolling_pin_sink_place\").setPosition(rolling_pin_sink_point).setShape(ry.ST.marker, size=[0.02])\n",
    "\n",
    "komo = ry.KOMO()\n",
    "komo.setConfig(C, True)\n",
    "komo.setTiming(2., 1, 5., 0)\n",
    "komo.addControlObjective([], 0, 1e-0)\n",
    "komo.addObjective([], ry.FS.accumulatedCollisions, [], ry.OT.eq)\n",
    "komo.addObjective([], ry.FS.jointLimits, [], ry.OT.ineq)\n",
    "\n",
    "komo.addObjective([1.], ry.FS.poseDiff, ['l_gripper', 'rolling_pin_gripper_point1'], ry.OT.eq, [1e1])\n",
    "komo.addObjective([2.], ry.FS.poseDiff, ['l_gripper', 'rolling_pin_gripper_point2'], ry.OT.eq, [1e1])\n",
    "\n",
    "solver = ry.NLP_Solver()\n",
    "solver.setProblem(komo.nlp())\n",
    "solver.setOptions(stopTolerance=1e-2, verbose=4)\n",
    "ret = solver.solve()\n",
    "print(ret)\n",
    "\n",
    "komo.view(False, \"waypoints solution for rolling-pin\")\n",
    "\n",
    "path_rolling_pin = komo.getPath()\n",
    "\n",
    "rolling_pin_sink_target = [-1, -0.3, 1]  \n",
    "\n",
    "C.addFrame(\"rolling_pin_sink_target\").setPosition(rolling_pin_sink_target).setShape(ry.ST.marker, size=[0.02])\n",
    "\n",
    "komo = ry.KOMO()\n",
    "komo.setConfig(C, True)\n",
    "komo.setTiming(1., 1, 5., 0) \n",
    "komo.addControlObjective([], 0, 1e-0)\n",
    "komo.addObjective([], ry.FS.accumulatedCollisions, [], ry.OT.eq)\n",
    "komo.addObjective([], ry.FS.jointLimits, [], ry.OT.ineq)\n",
    "\n",
    "komo.addObjective(\n",
    "    [1.], \n",
    "    ry.FS.poseDiff,\n",
    "    ['l_gripper', 'rolling_pin_sink_target'],  \n",
    "    ry.OT.eq,\n",
    "    [1e1]\n",
    ")\n",
    "\n",
    "solver = ry.NLP_Solver()\n",
    "solver.setProblem(komo.nlp())\n",
    "solver.setOptions(stopTolerance=1e-2, verbose=4)\n",
    "ret = solver.solve()\n",
    "print(ret)\n",
    "\n",
    "path2_rolling_pin = komo.getPath()\n",
    "\n",
    "bot = ry.BotOp(C, False)\n",
    "bot.home(C)\n",
    "\n",
    "bot.move(path_rolling_pin, [2.0, 3.0])\n",
    "while bot.getTimeToEnd() > 0:\n",
    "    bot.sync(C, 0.1)\n",
    "\n",
    "bot.gripperCloseGrasp(ry._left, \"rolling-pin_0\")  \n",
    "while not bot.gripperDone(ry._left):\n",
    "    bot.sync(C, 0.1)\n",
    "\n",
    "bot.move(path2_rolling_pin, [3.0])\n",
    "while bot.getTimeToEnd() > 0:\n",
    "    bot.sync(C, 0.1)\n",
    "\n",
    "bot.gripperMove(ry._left, width=.75, speed=.2)\n",
    "while not bot.gripperDone(ry._left):\n",
    "    bot.sync(C, .1)    \n",
    "\n",
    "bot.home(C)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a7fc9027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{ time: 0, evals: 14, done: 1, feasible: 1, sos: 5.6177, f: 0, ineq: 0, eq: 0.0544175 }\n",
      "{ time: 0.109375, evals: 1000, done: 1, feasible: 0, sos: 21.6912, f: 0, ineq: 0, eq: 3.37942 }\n"
     ]
    }
   ],
   "source": [
    "soap_grasp_point1 = p1_soap\n",
    "soap_grasp_point2 = p2_soap\n",
    "\n",
    "soap_grasp_middle = (soap_grasp_point1 + soap_grasp_point2) / 2\n",
    "\n",
    "soap_gripper_point1 = soap_grasp_middle + 0.04 * unit_normal_sabun\n",
    "soap_gripper_point2 = soap_grasp_middle - 0.04 * unit_normal_sabun\n",
    "\n",
    "C.addFrame(\"soap_gripper_point1\").setPosition(soap_gripper_point1).setShape(ry.ST.marker, size=[0.02])\n",
    "C.addFrame(\"soap_gripper_point2\").setPosition(soap_gripper_point2).setShape(ry.ST.marker, size=[0.02])\n",
    "\n",
    "soap_sink_point = [0.6, 0.0, 0.7]  \n",
    "\n",
    "C.addFrame(\"soap_sink_place\").setPosition(soap_sink_point).setShape(ry.ST.marker, size=[0.02])\n",
    "\n",
    "komo = ry.KOMO()\n",
    "komo.setConfig(C, True)\n",
    "komo.setTiming(2., 1, 5., 0)\n",
    "komo.addControlObjective([], 0, 1e-0)\n",
    "komo.addObjective([], ry.FS.accumulatedCollisions, [], ry.OT.eq)\n",
    "komo.addObjective([], ry.FS.jointLimits, [], ry.OT.ineq)\n",
    "\n",
    "komo.addObjective([1.], ry.FS.poseDiff, ['l_gripper', 'soap_gripper_point1'], ry.OT.eq, [1e1])\n",
    "komo.addObjective([2.], ry.FS.poseDiff, ['l_gripper', 'soap_gripper_point2'], ry.OT.eq, [1e1])\n",
    "\n",
    "solver = ry.NLP_Solver()\n",
    "solver.setProblem(komo.nlp())\n",
    "solver.setOptions(stopTolerance=1e-2, verbose=4)\n",
    "ret = solver.solve()\n",
    "print(ret)\n",
    "\n",
    "komo.view(False, \"waypoints solution for soap\")\n",
    "\n",
    "path_soap = komo.getPath()\n",
    "\n",
    "soap_sink_target = [-1, -0.3, 1]  \n",
    "\n",
    "C.addFrame(\"soap_sink_target\").setPosition(soap_sink_target).setShape(ry.ST.marker, size=[0.02])\n",
    "\n",
    "komo = ry.KOMO()\n",
    "komo.setConfig(C, True)\n",
    "komo.setTiming(1., 1, 5., 0)  \n",
    "komo.addControlObjective([], 0, 1e-0)\n",
    "komo.addObjective([], ry.FS.accumulatedCollisions, [], ry.OT.eq)\n",
    "komo.addObjective([], ry.FS.jointLimits, [], ry.OT.ineq)\n",
    "\n",
    "komo.addObjective(\n",
    "    [1.],  \n",
    "    ry.FS.poseDiff,\n",
    "    ['l_gripper', 'soap_sink_target'],  \n",
    "    ry.OT.eq,\n",
    "    [1e1]\n",
    ")\n",
    "\n",
    "\n",
    "solver = ry.NLP_Solver()\n",
    "solver.setProblem(komo.nlp())\n",
    "solver.setOptions(stopTolerance=1e-2, verbose=4)\n",
    "ret = solver.solve()\n",
    "print(ret)\n",
    "\n",
    "path2_soap = komo.getPath()\n",
    "\n",
    "bot = ry.BotOp(C, False)\n",
    "bot.home(C)\n",
    "\n",
    "bot.move(path_soap, [2.0, 3.0])\n",
    "while bot.getTimeToEnd() > 0:\n",
    "    bot.sync(C, 0.1)\n",
    "\n",
    "\n",
    "bot.gripperCloseGrasp(ry._left, \"soap_0\")  \n",
    "while not bot.gripperDone(ry._left):\n",
    "    bot.sync(C, 0.1)\n",
    "\n",
    "bot.move(path2_soap, [3.0])  \n",
    "while bot.getTimeToEnd() > 0:\n",
    "    bot.sync(C, 0.1)\n",
    "\n",
    "bot.gripperMove(ry._left, width=.01, speed=.2)\n",
    "while not bot.gripperDone(ry._left):\n",
    "    bot.sync(C, .1)    \n",
    "\n",
    "bot.home(C)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c1217056",
   "metadata": {},
   "outputs": [],
   "source": [
    "del bot\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
